# PromptShield ‚Äî AI Traffic Firewall for Developers

PromptShield is a local proxy that monitors, controls, and sanitizes AI/LLM traffic.

## Problem

Developers regularly send prompts, code snippets, and tokens to services such as ChatGPT, Copilot, and other LLM APIs. Without an explicit control point, teams have limited visibility into what leaves developer machines, and limited ability to enforce policy before data is sent. This creates practical security and compliance risks:

- accidental leakage of secrets or internal code
- unmanaged access to external AI endpoints
- poor auditability for incident response or governance

## Solution

PromptShield runs locally as a security proxy between developer tools and LLM providers. It can:

- intercept outbound traffic
- apply policy decisions (`allow`, `block`, `mitm`)
- optionally inspect and sanitize request content
- produce structured audit logs for traceability

## Key Features

- HTTP/HTTPS proxy for local AI traffic control
- selective MITM (TLS interception) per configured domains
- policy engine with `allow` / `block` / `mitm` actions
- prompt sanitization for PII and common secret patterns
- JSONL audit logging for security analysis
- system proxy integration on macOS (`psctl proxy on`)

## Architecture (Short)

```text
App ‚Üí PromptShield ‚Üí LLM APIs
```

PromptShield consists of four core layers:

- **Proxy layer**: receives HTTP/HTTPS traffic from local clients
- **Policy engine**: evaluates host-based rules and decides action
- **Sanitizer**: redacts configured sensitive data patterns during inspected flows
- **Audit logger**: stores request events as JSONL records

For deeper details, see [docs/architecture.md](docs/architecture.md).

## Quick Start

### 1) Build

```bash
go build ./cmd/psd
go build ./cmd/psctl
```

### 2) Generate local CA

```bash
./psctl ca init
```

### 3) Install certificate (macOS)

1. Open the generated certificate:
   ```bash
   open ~/.promptshield/ca/cert.pem
   ```
2. Add it to **Keychain Access**.
3. Open the certificate trust settings.
4. Set **When using this certificate** to **Always Trust**.

### 4) Start proxy

```bash
./psctl start
```

Default listener:

```text
http://localhost:8080
```

### 5) Enable system proxy (macOS)

```bash
./psctl proxy on
```

You can verify status with:

```bash
./psctl proxy status
```

## Demo

```bash
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer sk-123..."
```

When your system or shell proxy points to PromptShield:

- the request is routed through the local proxy
- policy rules are evaluated for `api.openai.com`
- sensitive values can be masked in logged metadata

## Example Output

Example audit event (JSONL):

```json
{
  "ts": "2026-01-14T10:22:31Z",
  "method": "POST",
  "host": "api.openai.com",
  "path": "/v1/chat/completions",
  "decision": "mitm",
  "sanitized": true,
  "sanitized_items": ["api_key", "email"],
  "status": 200,
  "latency_ms": 241
}
```

## Configuration

See [docs/configuration.md](docs/configuration.md) for full configuration reference and policy examples.

## Testing

–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π:

```bash
make test
```

–≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞:
1. üê≥ –°–æ–±–∏—Ä–∞–µ—Ç Docker –æ–±—Ä–∞–∑—ã –¥–ª—è proxy –∏ echo —Å–µ—Ä–≤–∏—Å–æ–≤
2. ‚è≥ –ñ–¥–µ—Ç, –ø–æ–∫–∞ —Å–µ—Ä–≤–∏—Å—ã –ø—Ä–æ–π–¥—É—Ç healthcheck
3. üß™ –ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã (`go test ./...`)
4. üßπ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ—Å—Ç–æ–≤

–í—Å–µ —Ç–µ—Å—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è —Ä—è–¥–æ–º —Å –∫–æ–¥–æ–º:
- `internal/*/` - unit —Ç–µ—Å—Ç—ã –≤ `*_test.go` —Ñ–∞–π–ª–∞—Ö
- `internal/integration/` - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã —Å proxy –∏ echo

### –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã –ª–æ–∫–∞–ª—å–Ω–æ (–±–µ–∑ Docker)
go test ./...

# –° –ø—Ä–æ–≤–µ—Ä–∫–æ–π race conditions
go test -race ./...
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** Integration —Ç–µ—Å—Ç—ã —Ç—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è `PROXY_ADDR` –∏ `ECHO_ADDR`.

## Performance testing

–î–ª—è –∑–∞–º–µ—Ä–∞ latency –ø–æ —ç—Ç–∞–ø–∞–º –∑–∞–ø—Ä–æ—Å–∞ (sanitize, ttfb, upstream, response) –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç:

```bash
./scripts/benchmark_trace.sh
```

–°–∫—Ä–∏–ø—Ç –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç 2 –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π proxy `http://localhost:8080`:
1. `GET /v1/models`
2. `POST /v1/chat/completions`

–ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º:
1. –ü–æ–¥–Ω–∏–º–∏ PromptShield (`./psctl start`)
2. –£–±–µ–¥–∏—Å—å, —á—Ç–æ –¥–æ—Å—Ç—É–ø–µ–Ω –≤–Ω–µ—à–Ω–∏–π API endpoint (–Ω–∞–ø—Ä–∏–º–µ—Ä `api.openai.com`)

–ü—Ä–∏–º–µ—Ä —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∫–æ–º–∞–Ω–¥ –∏–∑ —Å–∫—Ä–∏–ø—Ç–∞:

```bash
curl -x http://localhost:8080 https://api.openai.com/v1/models -k

curl -x http://localhost:8080 https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"message":"test"}' -k
```

–õ–æ–≥–∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–∏—à—É—Ç—Å—è –≤ stdout –ø—Ä–æ—Ü–µ—Å—Å–∞ proxy (—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10% –∑–∞–ø—Ä–æ—Å–æ–≤). –ò—â–∏ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞:

```text
trace=<id> total=<d> sanitize=<d> ttfb=<d> upstream=<d> response=<d> first_byte_latency=<d> streaming=<bool>
```

## Security

- MITM inspection is optional and domain-scoped.
- Processing is local to your machine.
- PromptShield does not require remote control-plane services for core operation.

Read the full security guidance in [docs/security.md](docs/security.md).

## Roadmap

- system-level network agent mode (VPN/TUN)
- VS Code extension for developer workflow visibility
- enterprise policy packs, identity integration, and centralized audit shipping

## Disclaimer

PromptShield is a traffic interception tool. You should use it only in environments you trust and understand. Enabling HTTPS interception requires installing and trusting a local CA certificate. This project is intended for local development, security testing, and controlled internal usage.
